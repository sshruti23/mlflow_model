name: Upload artifacts to databricks

on: [push]

jobs:
  training:
#    if: github.actor == 'sshruti23'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
      - name : Install Dependencies
        run : |
            python --version 
            pip install databricks-cli 
      - name : Create Model Library Python Egg File
        run : |
            ls -la
            python setup.py bdist --formats=egg
            mv dist/*.egg dist/model.egg
            ls -la
      - name: Authenticate To Databricks Workspace
        run: |
            echo ${{ secrets.AWS_DB_TOKEN }} > token-file 
            databricks configure --host ${{ secrets.AWS_DB_HOST }} --token-file token-file 
            rm -f token-file
      - name: Upload egg file to databricks workspace
        run: |
            dbfs cp --overwrite dist/*.egg  dbfs:/FileStore/
#      - name: Submit A Databricks Job For Training model
#        run: |
#             curl -X POST https://dbc-024af671-5f60.cloud.databricks.com/api/2.1/jobs/runs/submit \
#              -H "Authorization:Bearer ${{ secrets.AWS_DB_TOKEN }}" \
#              -H "Content-Type: application/json" \
#              --data @pipeline_request_body/training.json
#  register:
#    if: github.actor == 'sshruti23'
#    runs-on: ubuntu-latest
#    needs: training
#    environment: 'register'
#
#    steps:
#      - name: Checkout repo
#        uses: actions/checkout@v2
#      - name : Echo Something
#        run : |
#              echo "I'm a echo from prod stage"