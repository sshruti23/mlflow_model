name: Deploy latest repo code as mlproject on databricks

jobs:
  staging:
    if: github.actor == 'sshruti23'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
      - name : Install Dependencies
        run : |
              python --version 
              pip install databricks-cli 
              pip install mlflow
      - name: Authenticate To Databricks Workspace
        run: | 
             echo ${{ secrets.AWS_DB_TOKEN }} > token-file 
             databricks configure --host ${{ secrets.AWS_DB_HOST }} --token-file token-file 
             rm -f token-file
      - name: Run MLFlow Project in Databricks
        run: |
             export MLFLOW_TRACKING_URI=databricks
             mlflow run  https://github.com/sshruti23/mlflow_model.git#binary_classification \
              -b databricks \
              --backend-config data.json  \
              --entry-point train.py \
              --experiment-id 3974792302628189
  prod:
    if: github.actor == 'sshruti23'
    runs-on: ubuntu-latest
    needs: staging
    environment: 'prod'

    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
      - name : Install Dependencies
        run : |
              python --version 
              pip install databricks-cli 
              pip install mlflow
      - name: Authenticate To Databricks Workspace
        run: | 
             echo ${{ secrets.AWS_DB_TOKEN }} > token-file 
             databricks configure --host ${{ secrets.AWS_DB_HOST }} --token-file token-file 
             rm -f token-file
      - name: Run MLFlow Project in Databricks
        run: |
             export MLFLOW_TRACKING_URI=databricks
             mlflow run  https://github.com/sshruti23/mlflow_model.git#binary_classification \
              -b databricks \
              --backend-config data.json  \
              --entry-point inference.py \
              --experiment-id 3974792302628189
